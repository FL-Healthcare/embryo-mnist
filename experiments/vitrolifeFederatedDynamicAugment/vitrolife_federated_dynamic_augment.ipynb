{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f479bb17-c2da-496e-b767-7aadad74f3e5",
   "metadata": {},
   "source": [
    "### Options:\n",
    "* NumberOfClients = 1-23\n",
    "    * *Client processes that the simulation starts*\n",
    "* FractionOfClients = [0,1]  \n",
    "    * *Percentage of clients perticipating each training round for fit/eval*\n",
    "* NumberOfRounds = 1-*\n",
    "    * *Numbers of federated rounds*\n",
    "* BalancingStrategy = 'OverSampling'/'ClassWeights'/'None'\n",
    "    * *Compensate for dataset class imbalance*\n",
    "* DataAugmentation = 'True'/'False'\n",
    "    * *To augment data sample while training, to avoid overfit*\n",
    "* BatchSize = 16/32/64/128\n",
    "    * *Size of each batch getting fed to the network*\n",
    "* NumberOfEpochs = 1-*\n",
    "    * *Number of local epochs on clients*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970de7ee-45e2-4805-8eb6-8495250279dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-02 11:12:33.544371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:33.935518: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "-n Embryo-R300-E1-B16-OverSampling-Aggresive-DA -c 23 -f 1.0 -r 300 -bs OverSampling -d True -b 16 -e 1\n",
      "Init server\n",
      "Number of rounds 300, fraction fit/eval 1.0, experiment name Embryo-R300-E1-B16-OverSampling-Aggresive-DA\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "2022-06-02 11:12:47.588005: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:47.712450: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111246-2srpeta6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdainty-flower-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/2srpeta6\u001b[0m\n",
      "INFO flower 2022-06-02 11:12:49,484 | app.py:109 | Flower server running (300 rounds), SSL is disabled\n",
      "INFO flower 2022-06-02 11:12:49,484 | server.py:84 | Initializing global parameters\n",
      "INFO flower 2022-06-02 11:12:49,484 | server.py:249 | Requesting initial parameters from one random client\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "2022-06-02 11:12:57.459779: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.473679: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.490852: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.500516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.534460: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.558349: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.570917: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.581378: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.588309: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.596193: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.597222: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.607520: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.613640: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.629819: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.642147: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.642858: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.658173: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.670222: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.670667: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.678978: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.699238: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.708074: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.713597: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.732593: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.733900: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.743065: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.760145: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.762079: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.765718: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.773729: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.776814: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.784412: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.790662: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "2022-06-02 11:12:57.808393: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "2022-06-02 11:12:57.812890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "2022-06-02 11:12:57.826356: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.831983: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:57.852773: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.853503: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "2022-06-02 11:12:57.888893: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.907946: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.907945: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "2022-06-02 11:12:57.929952: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "2022-06-02 11:12:57.958393: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "2022-06-02 11:12:57.978029: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-02 11:12:57.978720: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-j50fh9bj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-1g0pz4cj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-1atcx8xt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbrisk-wind-9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/j50fh9bj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvibrant-spaceship-11\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/1g0pz4cj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-1d1wrnqg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myoung-surf-8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/1atcx8xt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-2t9f1w8n\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-2cgt1ymr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mglamorous-armadillo-6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/1d1wrnqg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflowing-bird-3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/2t9f1w8n\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-egeyxgeo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlikely-sunset-7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-3g21r10c\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/2cgt1ymr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-3i5u1hbv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-2xpcb2ty\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrevived-haze-14\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/egeyxgeo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfluent-darkness-2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/3g21r10c\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-2dlovn2h\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mresilient-bird-10\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/3i5u1hbv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlively-pyramid-5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/2xpcb2ty\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-1ddhzagi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mleafy-thunder-21\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/2dlovn2h\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msleek-valley-15\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/1ddhzagi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-kirj31z9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmisty-sunset-17\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/kirj31z9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-2h1pnrh1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgenerous-pyramid-4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/2h1pnrh1\u001b[0m\n",
      "Using oversampler strategy in dataloader\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Cleaning old model folder\n",
      "New model directory is created!\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Using oversampler strategy in dataloader\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Using data augmentation\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Using data augmentation\n",
      "Client 16 is using CPU\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Using oversampler strategy in dataloader\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Using data augmentation\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-mqwtfuf4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-1s4byw3p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "Using oversampler strategy in dataloader\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mswift-snow-20\u001b[0m\n",
      "Using data augmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/mqwtfuf4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmild-capybara-16\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/1s4byw3p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-2i7km8h1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcolorful-snowflake-18\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/2i7km8h1\u001b[0m\n",
      "Client 4 is using GPU\n",
      "Client 5 is using GPU\n",
      "Client 9 is using CPU\n",
      "Client 2 is using GPU\n",
      "Client 12 is using GPU\n",
      "Client 3 is using GPU\n",
      "Client 11 is using CPU\n",
      "Client 1 is using GPU\n",
      "Client 0 is using CPU\n",
      "Client 22 is using CPU\n",
      "Client 21 is using CPU\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-1px3gscu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Using oversampler strategy in dataloader\n",
      "Client 8 is using GPU\n",
      "Using data augmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgentle-galaxy-22\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/1px3gscu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-2017y1hc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlucky-breeze-19\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/2017y1hc\u001b[0m\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "2022-06-02 11:12:59.540079: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:59.544741: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:59.540351: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:59.541248: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:59.540914: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-11yhsjxe\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwild-haze-12\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/11yhsjxe\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-cdsm7p67\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meffortless-gorge-13\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/cdsm7p67\u001b[0m\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "2022-06-02 11:12:59.645713: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-28xkzqav\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mapricot-bee-23\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/28xkzqav\u001b[0m\n",
      "Client 15 is using CPU\n",
      "Client 13 is using CPU\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Client 19 is using CPU\n",
      "Client 6 is using CPU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/vitrolifeFederatedDynamicAugment/wandb/run-20220602_111256-3avgbzp0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlaced-cherry-24\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-DATEST/runs/3avgbzp0\u001b[0m\n",
      "2022-06-02 11:12:59.710843: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:59.714464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Client 10 is using CPU\n",
      "Client 14 is using CPU\n",
      "Client 20 is using GPU\n",
      "2022-06-02 11:12:59.731634: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:59.731423: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO flower 2022-06-02 11:12:59,755 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-06-02 11:12:59,757 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:12:59,758 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "INFO flower 2022-06-02 11:12:59,758 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "INFO flower 2022-06-02 11:12:59,758 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-06-02 11:12:59,759 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-06-02 11:12:59,759 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "Client 17 is using GPU\n",
      "DEBUG flower 2022-06-02 11:12:59,759 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:12:59,760 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:12:59,760 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:12:59,760 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:12:59,761 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:12:59,761 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:12:59,761 | connection.py:39 | ChannelConnectivity.READY\n",
      "DEBUG flower 2022-06-02 11:12:59,762 | connection.py:39 | ChannelConnectivity.READY\n",
      "Using oversampler strategy in dataloader\n",
      "DEBUG flower 2022-06-02 11:12:59,763 | connection.py:39 | ChannelConnectivity.READY\n",
      "Using data augmentation\n",
      "INFO flower 2022-06-02 11:12:59,768 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-06-02 11:12:59,768 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:12:59,769 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:12:59,770 | connection.py:39 | ChannelConnectivity.READY\n",
      "2022-06-02 11:12:59.750826: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:59.758075: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO flower 2022-06-02 11:12:59,795 | server.py:252 | Received initial parameters from one random client\n",
      "INFO flower 2022-06-02 11:12:59,796 | server.py:86 | Evaluating initial parameters\n",
      "INFO flower 2022-06-02 11:12:59,796 | server.py:99 | FL starting\n",
      "INFO flower 2022-06-02 11:12:59,857 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-06-02 11:12:59,858 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:12:59,858 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:12:59,859 | connection.py:39 | ChannelConnectivity.READY\n",
      "Client 7 is using GPU\n",
      "INFO flower 2022-06-02 11:12:59,914 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-06-02 11:12:59,915 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "INFO flower 2022-06-02 11:12:59,922 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-06-02 11:12:59,923 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "Client 18 is using GPU\n",
      "DEBUG flower 2022-06-02 11:12:59,924 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:12:59,924 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-06-02 11:12:59,940 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-06-02 11:12:59,940 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:12:59,941 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:12:59,941 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-06-02 11:12:59,941 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-06-02 11:12:59,942 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:12:59,943 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:12:59,943 | connection.py:39 | ChannelConnectivity.READY\n",
      "DEBUG flower 2022-06-02 11:12:59,948 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:12:59,948 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-06-02 11:12:59,988 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-06-02 11:12:59,989 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:12:59,990 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:12:59,990 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-06-02 11:13:00,011 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-06-02 11:13:00,013 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:13:00,013 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:13:00,014 | connection.py:39 | ChannelConnectivity.READY\n",
      "2022-06-02 11:12:59.540077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:59.540467: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:59.540077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:13:00.810490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14509 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2022-06-02 11:12:59.540077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:59.540091: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:59.762057: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:59.930192: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:59.920584: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:59.547139: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:12:59.761176: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:13:00.810335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14509 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2022-06-02 11:13:00.810497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14509 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2022-06-02 11:12:59.540353: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 11:13:00.810563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14509 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2022-06-02 11:13:00.810154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14509 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2022-06-02 11:13:00.810292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14509 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2022-06-02 11:13:00.810260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14509 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2022-06-02 11:13:00.810438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14509 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2022-06-02 11:13:00.810393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14509 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2022-06-02 11:13:00.810538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14509 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2022-06-02 11:13:00.810198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14509 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "INFO flower 2022-06-02 11:13:00,996 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "INFO flower 2022-06-02 11:13:00,996 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "INFO flower 2022-06-02 11:13:00,996 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "INFO flower 2022-06-02 11:13:00,996 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-06-02 11:13:00,997 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "INFO flower 2022-06-02 11:13:00,997 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "INFO flower 2022-06-02 11:13:00,997 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-06-02 11:13:00,997 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "INFO flower 2022-06-02 11:13:00,997 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-06-02 11:13:00,997 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:13:00,997 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:13:00,997 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:13:00,997 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:13:00,997 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:13:00,997 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:13:00,997 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:13:00,998 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:13:00,998 | connection.py:39 | ChannelConnectivity.READY\n",
      "DEBUG flower 2022-06-02 11:13:00,998 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:13:00,998 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:13:00,998 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-06-02 11:13:00,998 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-06-02 11:13:00,998 | connection.py:39 | ChannelConnectivity.READY\n",
      "DEBUG flower 2022-06-02 11:13:00,998 | connection.py:39 | ChannelConnectivity.READY\n",
      "DEBUG flower 2022-06-02 11:13:00,998 | connection.py:39 | ChannelConnectivity.READY\n",
      "DEBUG flower 2022-06-02 11:13:00,998 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:13:00,999 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:13:00,999 | connection.py:39 | ChannelConnectivity.READY\n",
      "DEBUG flower 2022-06-02 11:13:00,999 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:13:01,001 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-06-02 11:13:01,008 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "INFO flower 2022-06-02 11:13:01,008 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-06-02 11:13:01,009 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:13:01,009 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:13:01,010 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:13:01,010 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-06-02 11:13:01,013 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-06-02 11:13:01,014 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-06-02 11:13:01,015 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:13:01,015 | connection.py:39 | ChannelConnectivity.READY\n",
      "DEBUG flower 2022-06-02 11:13:01,015 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:13:01,016 | connection.py:39 | ChannelConnectivity.READY\n",
      "DEBUG flower 2022-06-02 11:13:01,036 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-06-02 11:13:01,037 | connection.py:39 | ChannelConnectivity.READY\n",
      "DEBUG flower 2022-06-02 11:13:01,037 | server.py:198 | fit_round: strategy sampled 23 clients (out of 23)\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "2022-06-02 11:13:04.669444: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-06-02 11:13:04.669546: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-06-02 11:13:04.671075: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-06-02 11:13:04.675830: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-06-02 11:13:04.681561: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-06-02 11:13:04.689176: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-06-02 11:13:04.690047: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-06-02 11:13:04.697692: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-06-02 11:13:04.720921: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-06-02 11:13:04.725760: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-06-02 11:13:04.739339: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-06-02 11:13:10.075200: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-02 11:13:10.075404: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-02 11:13:10.101378: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-02 11:13:10.101489: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-02 11:13:10.110404: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-02 11:13:10.111361: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-02 11:13:10.144025: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-02 11:13:10.153088: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-02 11:13:10.165384: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-02 11:13:10.198068: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-02 11:13:10.239488: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-02 11:13:10.774366: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-02 11:13:10.774895: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-02 11:13:10.779207: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-02 11:13:10.779412: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-02 11:13:10.780748: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-02 11:13:10.805277: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-02 11:13:10.854046: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-02 11:13:10.896182: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-02 11:13:10.934679: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-02 11:13:10.943684: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-02 11:13:10.946918: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "DEBUG flower 2022-06-02 11:15:06,863 | server.py:210 | fit_round received 23 results and 0 failures\n",
      "WARNING flower 2022-06-02 11:15:07,050 | fedavg.py:237 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flower 2022-06-02 11:15:07,050 | server.py:155 | evaluate_round: strategy sampled 23 clients (out of 23)\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.trackable_utils has been moved to tensorflow.python.trackable.trackable_utils. The old module will be deleted in version 2.11.\n",
      "INFO:tensorflow:Assets written to: ./models/Embryo-R300-E1-B16-OverSampling-Aggresive-DA/R-1/assets\n",
      "DEBUG flower 2022-06-02 11:15:15,741 | server.py:167 | evaluate_round received 23 results and 0 failures\n",
      "Current time 146.27265119552612\n",
      "Server Metric aggregation 1==300\n",
      "DEBUG flower 2022-06-02 11:15:15,741 | server.py:198 | fit_round: strategy sampled 23 clients (out of 23)\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "DEBUG flower 2022-06-02 11:17:16,985 | server.py:210 | fit_round received 23 results and 0 failures\n",
      "DEBUG flower 2022-06-02 11:17:17,142 | server.py:155 | evaluate_round: strategy sampled 23 clients (out of 23)\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70840114>, <tf.Tensor: shape=(), dtype=float32, numpy=0.74176383>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69479>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7021393>]\n",
      "cleint: 22 is overfitting - Apply Aggresive\n",
      "cleint: 21 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70302653>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7259594>]\n",
      "cleint: 9 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7091421>, <tf.Tensor: shape=(), dtype=float32, numpy=0.74163914>]\n",
      "cleint: 19 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70733047>, <tf.Tensor: shape=(), dtype=float32, numpy=0.740085>]\n",
      "cleint: 13 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70350313>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72473073>]\n",
      "cleint: 16 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7031487>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7274393>]\n",
      "cleint: 11 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.6998859>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7183719>]\n",
      "cleint: 14 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69859135>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7133168>]\n",
      "cleint: 10 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70943373>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7465631>]\n",
      "cleint: 15 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.68294483>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6660871>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.701369>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72298807>]\n",
      "cleint: 6 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.713865>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75901634>]\n",
      "cleint: 18 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70907784>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7474029>]\n",
      "cleint: 8 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7121571>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75333935>]\n",
      "cleint: 3 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70754814>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7411814>]\n",
      "cleint: 20 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.71419823>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7585523>]\n",
      "cleint: 12 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69888693>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7128699>]\n",
      "cleint: 4 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.6864988>, <tf.Tensor: shape=(), dtype=float32, numpy=0.677989>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7067927>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7385066>]\n",
      "cleint: 5 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7064629>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7376922>]\n",
      "cleint: 17 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.71426535>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7599767>]\n",
      "cleint: 1 is overfitting - Apply Aggresive\n",
      "INFO:tensorflow:Assets written to: ./models/Embryo-R300-E1-B16-OverSampling-Aggresive-DA/R-2/assets\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7118388>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75226825>]\n",
      "cleint: 7 is overfitting - Apply Aggresive\n",
      "DEBUG flower 2022-06-02 11:17:26,095 | server.py:167 | evaluate_round received 23 results and 0 failures\n",
      "Current time 130.3538417816162\n",
      "Server Metric aggregation 2==300\n",
      "DEBUG flower 2022-06-02 11:17:26,095 | server.py:198 | fit_round: strategy sampled 23 clients (out of 23)\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loopStarting custom training loop\n",
      "\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "DEBUG flower 2022-06-02 11:19:30,438 | server.py:210 | fit_round received 23 results and 0 failures\n",
      "DEBUG flower 2022-06-02 11:19:30,602 | server.py:155 | evaluate_round: strategy sampled 23 clients (out of 23)\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70350313>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72473073>, <tf.Tensor: shape=(), dtype=float32, numpy=0.73350406>]\n",
      "cleint: 16 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70302653>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7259594>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7249581>]\n",
      "cleint: 9 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7091421>, <tf.Tensor: shape=(), dtype=float32, numpy=0.74163914>, <tf.Tensor: shape=(), dtype=float32, numpy=0.756078>]\n",
      "cleint: 19 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69479>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7021393>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70992404>]\n",
      "cleint: 21 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70733047>, <tf.Tensor: shape=(), dtype=float32, numpy=0.740085>, <tf.Tensor: shape=(), dtype=float32, numpy=0.749718>]\n",
      "cleint: 13 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70840114>, <tf.Tensor: shape=(), dtype=float32, numpy=0.74176383>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75067174>]\n",
      "cleint: 22 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7031487>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7274393>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7288362>]\n",
      "cleint: 11 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69859135>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7133168>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7235203>]\n",
      "cleint: 10 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.6998859>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7183719>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72748804>]\n",
      "cleint: 14 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70943373>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7465631>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7614266>]\n",
      "cleint: 15 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.68294483>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6660871>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6594762>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.701369>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72298807>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7390199>]\n",
      "cleint: 6 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7121571>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75333935>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7757112>]\n",
      "cleint: 3 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.713865>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75901634>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7734025>]\n",
      "cleint: 18 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70754814>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7411814>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7612294>]\n",
      "cleint: 20 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70907784>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7474029>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7699877>]\n",
      "cleint: 8 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.71419823>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7585523>, <tf.Tensor: shape=(), dtype=float32, numpy=0.77847695>]\n",
      "cleint: 12 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69888693>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7128699>, <tf.Tensor: shape=(), dtype=float32, numpy=0.720524>]\n",
      "cleint: 4 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.6864988>, <tf.Tensor: shape=(), dtype=float32, numpy=0.677989>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6753171>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7067927>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7385066>, <tf.Tensor: shape=(), dtype=float32, numpy=0.757506>]\n",
      "cleint: 5 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7064629>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7376922>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7502136>]\n",
      "cleint: 17 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.71426535>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7599767>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7825958>]\n",
      "cleint: 1 is overfitting - Apply Aggresive\n",
      "INFO:tensorflow:Assets written to: ./models/Embryo-R300-E1-B16-OverSampling-Aggresive-DA/R-3/assets\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7118388>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75226825>, <tf.Tensor: shape=(), dtype=float32, numpy=0.77034885>]\n",
      "cleint: 7 is overfitting - Apply Aggresive\n",
      "DEBUG flower 2022-06-02 11:19:39,242 | server.py:167 | evaluate_round received 23 results and 0 failures\n",
      "Current time 133.14712834358215\n",
      "Server Metric aggregation 3==300\n",
      "DEBUG flower 2022-06-02 11:19:39,243 | server.py:198 | fit_round: strategy sampled 23 clients (out of 23)\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "DEBUG flower 2022-06-02 11:21:43,296 | server.py:210 | fit_round received 23 results and 0 failures\n",
      "DEBUG flower 2022-06-02 11:21:43,464 | server.py:155 | evaluate_round: strategy sampled 23 clients (out of 23)\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69479>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7021393>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70992404>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71025276>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7091421>, <tf.Tensor: shape=(), dtype=float32, numpy=0.74163914>, <tf.Tensor: shape=(), dtype=float32, numpy=0.756078>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7046397>]\n",
      "cleint: 21 is overfitting - Apply Aggresive\n",
      "cleint: 19 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70350313>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72473073>, <tf.Tensor: shape=(), dtype=float32, numpy=0.73350406>, <tf.Tensor: shape=(), dtype=float32, numpy=0.69395244>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70733047>, <tf.Tensor: shape=(), dtype=float32, numpy=0.740085>, <tf.Tensor: shape=(), dtype=float32, numpy=0.749718>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6718842>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70840114>, <tf.Tensor: shape=(), dtype=float32, numpy=0.74176383>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75067174>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71299994>]\n",
      "cleint: 22 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70302653>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7259594>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7249581>, <tf.Tensor: shape=(), dtype=float32, numpy=0.68527484>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7031487>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7274393>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7288362>, <tf.Tensor: shape=(), dtype=float32, numpy=0.69203496>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69859135>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7133168>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7235203>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71175796>]\n",
      "cleint: 10 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.6998859>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7183719>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72748804>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7025564>]\n",
      "cleint: 14 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70943373>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7465631>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7614266>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7393204>]\n",
      "cleint: 15 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.68294483>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6660871>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6594762>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6657097>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.701369>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72298807>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7390199>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7331773>]\n",
      "cleint: 6 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7121571>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75333935>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7757112>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75179726>]\n",
      "cleint: 3 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.713865>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75901634>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7734025>, <tf.Tensor: shape=(), dtype=float32, numpy=0.719786>]\n",
      "cleint: 18 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70907784>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7474029>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7699877>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7535939>]\n",
      "cleint: 8 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.71419823>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7585523>, <tf.Tensor: shape=(), dtype=float32, numpy=0.77847695>, <tf.Tensor: shape=(), dtype=float32, numpy=0.73532194>]\n",
      "cleint: 12 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70754814>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7411814>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7612294>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7542907>]\n",
      "cleint: 20 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69888693>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7128699>, <tf.Tensor: shape=(), dtype=float32, numpy=0.720524>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7098788>]\n",
      "cleint: 4 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.6864988>, <tf.Tensor: shape=(), dtype=float32, numpy=0.677989>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6753171>, <tf.Tensor: shape=(), dtype=float32, numpy=0.67873764>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7067927>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7385066>, <tf.Tensor: shape=(), dtype=float32, numpy=0.757506>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7415626>]\n",
      "cleint: 5 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7064629>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7376922>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7502136>, <tf.Tensor: shape=(), dtype=float32, numpy=0.717383>]\n",
      "cleint: 17 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.71426535>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7599767>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7825958>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7534451>]\n",
      "cleint: 1 is overfitting - Apply Aggresive\n",
      "INFO:tensorflow:Assets written to: ./models/Embryo-R300-E1-B16-OverSampling-Aggresive-DA/R-4/assets\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7118388>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75226825>, <tf.Tensor: shape=(), dtype=float32, numpy=0.77034885>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7428742>]\n",
      "cleint: 7 is overfitting - Apply Aggresive\n",
      "DEBUG flower 2022-06-02 11:21:52,556 | server.py:167 | evaluate_round received 23 results and 0 failures\n",
      "Current time 133.31395435333252\n",
      "DEBUG flower 2022-06-02 11:21:52,557 | server.py:198 | fit_round: strategy sampled 23 clients (out of 23)\n",
      "Server Metric aggregation 4==300\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "DEBUG flower 2022-06-02 11:23:56,311 | server.py:210 | fit_round received 23 results and 0 failures\n",
      "DEBUG flower 2022-06-02 11:23:56,470 | server.py:155 | evaluate_round: strategy sampled 23 clients (out of 23)\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70302653>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7259594>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7249581>, <tf.Tensor: shape=(), dtype=float32, numpy=0.68527484>, <tf.Tensor: shape=(), dtype=float32, numpy=0.67565393>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69479>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7021393>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70992404>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71025276>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70964736>]\n",
      "cleint: 21 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70840114>, <tf.Tensor: shape=(), dtype=float32, numpy=0.74176383>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75067174>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71299994>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70910716>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70733047>, <tf.Tensor: shape=(), dtype=float32, numpy=0.740085>, <tf.Tensor: shape=(), dtype=float32, numpy=0.749718>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6718842>, <tf.Tensor: shape=(), dtype=float32, numpy=0.65566754>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7091421>, <tf.Tensor: shape=(), dtype=float32, numpy=0.74163914>, <tf.Tensor: shape=(), dtype=float32, numpy=0.756078>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7046397>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7057889>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70350313>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72473073>, <tf.Tensor: shape=(), dtype=float32, numpy=0.73350406>, <tf.Tensor: shape=(), dtype=float32, numpy=0.69395244>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6889851>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7031487>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7274393>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7288362>, <tf.Tensor: shape=(), dtype=float32, numpy=0.69203496>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6879018>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69859135>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7133168>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7235203>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71175796>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7082522>]\n",
      "cleint: 10 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.6998859>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7183719>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72748804>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7025564>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70598376>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70943373>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7465631>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7614266>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7393204>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7462926>]\n",
      "cleint: 15 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.68294483>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6660871>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6594762>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6657097>, <tf.Tensor: shape=(), dtype=float32, numpy=0.66902876>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.701369>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72298807>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7390199>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7331773>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7372293>]\n",
      "cleint: 6 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.713865>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75901634>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7734025>, <tf.Tensor: shape=(), dtype=float32, numpy=0.719786>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70966566>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7121571>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75333935>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7757112>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75179726>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75111187>]\n",
      "cleint: 3 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70907784>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7474029>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7699877>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7535939>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7465267>]\n",
      "cleint: 8 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.71419823>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7585523>, <tf.Tensor: shape=(), dtype=float32, numpy=0.77847695>, <tf.Tensor: shape=(), dtype=float32, numpy=0.73532194>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7402101>]\n",
      "cleint: 12 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70754814>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7411814>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7612294>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7542907>, <tf.Tensor: shape=(), dtype=float32, numpy=0.751228>]\n",
      "cleint: 20 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69888693>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7128699>, <tf.Tensor: shape=(), dtype=float32, numpy=0.720524>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7098788>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71105576>]\n",
      "cleint: 4 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.6864988>, <tf.Tensor: shape=(), dtype=float32, numpy=0.677989>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6753171>, <tf.Tensor: shape=(), dtype=float32, numpy=0.67873764>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6781917>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7067927>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7385066>, <tf.Tensor: shape=(), dtype=float32, numpy=0.757506>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7415626>, <tf.Tensor: shape=(), dtype=float32, numpy=0.73193294>]\n",
      "cleint: 5 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7064629>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7376922>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7502136>, <tf.Tensor: shape=(), dtype=float32, numpy=0.717383>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7158809>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.71426535>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7599767>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7825958>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7534451>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7486205>]\n",
      "cleint: 1 is overfitting - Apply Aggresive\n",
      "INFO:tensorflow:Assets written to: ./models/Embryo-R300-E1-B16-OverSampling-Aggresive-DA/R-5/assets\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7118388>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75226825>, <tf.Tensor: shape=(), dtype=float32, numpy=0.77034885>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7428742>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7396205>]\n",
      "cleint: 7 is overfitting - Apply Aggresive\n",
      "DEBUG flower 2022-06-02 11:24:05,299 | server.py:167 | evaluate_round received 23 results and 0 failures\n",
      "Current time 132.74267482757568\n",
      "Server Metric aggregation 5==300\n",
      "DEBUG flower 2022-06-02 11:24:05,299 | server.py:198 | fit_round: strategy sampled 23 clients (out of 23)\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "DEBUG flower 2022-06-02 11:26:08,292 | server.py:210 | fit_round received 23 results and 0 failures\n",
      "DEBUG flower 2022-06-02 11:26:08,457 | server.py:155 | evaluate_round: strategy sampled 23 clients (out of 23)\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70350313>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72473073>, <tf.Tensor: shape=(), dtype=float32, numpy=0.73350406>, <tf.Tensor: shape=(), dtype=float32, numpy=0.69395244>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6889851>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6803054>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7091421>, <tf.Tensor: shape=(), dtype=float32, numpy=0.74163914>, <tf.Tensor: shape=(), dtype=float32, numpy=0.756078>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7046397>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7057889>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6892863>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70302653>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7259594>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7249581>, <tf.Tensor: shape=(), dtype=float32, numpy=0.68527484>, <tf.Tensor: shape=(), dtype=float32, numpy=0.67565393>, <tf.Tensor: shape=(), dtype=float32, numpy=0.66616416>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69479>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7021393>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70992404>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71025276>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70964736>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71059054>]\n",
      "cleint: 21 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70840114>, <tf.Tensor: shape=(), dtype=float32, numpy=0.74176383>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75067174>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71299994>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70910716>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7119327>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70733047>, <tf.Tensor: shape=(), dtype=float32, numpy=0.740085>, <tf.Tensor: shape=(), dtype=float32, numpy=0.749718>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6718842>, <tf.Tensor: shape=(), dtype=float32, numpy=0.65566754>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6568707>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7031487>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7274393>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7288362>, <tf.Tensor: shape=(), dtype=float32, numpy=0.69203496>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6879018>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6882015>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.6998859>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7183719>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72748804>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7025564>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70598376>, <tf.Tensor: shape=(), dtype=float32, numpy=0.69457614>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69859135>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7133168>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7235203>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71175796>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7082522>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7081976>]\n",
      "cleint: 10 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70943373>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7465631>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7614266>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7393204>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7462926>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72693795>]\n",
      "cleint: 15 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.701369>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72298807>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7390199>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7331773>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7372293>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7384572>]\n",
      "cleint: 6 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.68294483>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6660871>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6594762>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6657097>, <tf.Tensor: shape=(), dtype=float32, numpy=0.66902876>, <tf.Tensor: shape=(), dtype=float32, numpy=0.66983336>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.713865>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75901634>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7734025>, <tf.Tensor: shape=(), dtype=float32, numpy=0.719786>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70966566>, <tf.Tensor: shape=(), dtype=float32, numpy=0.69890887>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70907784>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7474029>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7699877>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7535939>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7465267>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7535017>]\n",
      "cleint: 8 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70754814>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7411814>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7612294>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7542907>, <tf.Tensor: shape=(), dtype=float32, numpy=0.751228>, <tf.Tensor: shape=(), dtype=float32, numpy=0.747717>]\n",
      "cleint: 20 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7121571>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75333935>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7757112>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75179726>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75111187>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75277245>]\n",
      "cleint: 3 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.71419823>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7585523>, <tf.Tensor: shape=(), dtype=float32, numpy=0.77847695>, <tf.Tensor: shape=(), dtype=float32, numpy=0.73532194>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7402101>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72775984>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69888693>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7128699>, <tf.Tensor: shape=(), dtype=float32, numpy=0.720524>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7098788>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71105576>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7085297>]\n",
      "cleint: 4 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.6864988>, <tf.Tensor: shape=(), dtype=float32, numpy=0.677989>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6753171>, <tf.Tensor: shape=(), dtype=float32, numpy=0.67873764>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6781917>, <tf.Tensor: shape=(), dtype=float32, numpy=0.67948866>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7067927>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7385066>, <tf.Tensor: shape=(), dtype=float32, numpy=0.757506>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7415626>, <tf.Tensor: shape=(), dtype=float32, numpy=0.73193294>, <tf.Tensor: shape=(), dtype=float32, numpy=0.73629504>]\n",
      "cleint: 5 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7064629>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7376922>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7502136>, <tf.Tensor: shape=(), dtype=float32, numpy=0.717383>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7158809>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7082265>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.71426535>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7599767>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7825958>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7534451>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7486205>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7419897>]\n",
      "cleint: 1 is overfitting - Apply Aggresive\n",
      "INFO:tensorflow:Assets written to: ./models/Embryo-R300-E1-B16-OverSampling-Aggresive-DA/R-6/assets\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7118388>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75226825>, <tf.Tensor: shape=(), dtype=float32, numpy=0.77034885>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7428742>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7396205>, <tf.Tensor: shape=(), dtype=float32, numpy=0.73521113>]\n",
      "cleint: 7 is overfitting - Apply Aggresive\n",
      "DEBUG flower 2022-06-02 11:26:17,206 | server.py:167 | evaluate_round received 23 results and 0 failures\n",
      "Current time 131.90698313713074\n",
      "DEBUG flower 2022-06-02 11:26:17,206 | server.py:198 | fit_round: strategy sampled 23 clients (out of 23)\n",
      "Server Metric aggregation 6==300\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "DEBUG flower 2022-06-02 11:28:19,828 | server.py:210 | fit_round received 23 results and 0 failures\n",
      "DEBUG flower 2022-06-02 11:28:19,968 | server.py:155 | evaluate_round: strategy sampled 29 clients (out of 29)\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7091421>, <tf.Tensor: shape=(), dtype=float32, numpy=0.74163914>, <tf.Tensor: shape=(), dtype=float32, numpy=0.756078>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7046397>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7057889>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6892863>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6535116>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69479>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7021393>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70992404>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71025276>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70964736>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71059054>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72095>]\n",
      "cleint: 21 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70350313>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72473073>, <tf.Tensor: shape=(), dtype=float32, numpy=0.73350406>, <tf.Tensor: shape=(), dtype=float32, numpy=0.69395244>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6889851>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6803054>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6462665>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70302653>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7259594>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7249581>, <tf.Tensor: shape=(), dtype=float32, numpy=0.68527484>, <tf.Tensor: shape=(), dtype=float32, numpy=0.67565393>, <tf.Tensor: shape=(), dtype=float32, numpy=0.66616416>, <tf.Tensor: shape=(), dtype=float32, numpy=0.66618943>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70840114>, <tf.Tensor: shape=(), dtype=float32, numpy=0.74176383>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75067174>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71299994>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70910716>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7119327>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6595687>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70733047>, <tf.Tensor: shape=(), dtype=float32, numpy=0.740085>, <tf.Tensor: shape=(), dtype=float32, numpy=0.749718>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6718842>, <tf.Tensor: shape=(), dtype=float32, numpy=0.65566754>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6568707>, <tf.Tensor: shape=(), dtype=float32, numpy=0.62509483>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7031487>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7274393>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7288362>, <tf.Tensor: shape=(), dtype=float32, numpy=0.69203496>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6879018>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6882015>, <tf.Tensor: shape=(), dtype=float32, numpy=0.68494487>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69859135>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7133168>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7235203>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71175796>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7082522>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7081976>, <tf.Tensor: shape=(), dtype=float32, numpy=0.69395065>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.6998859>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7183719>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72748804>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7025564>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70598376>, <tf.Tensor: shape=(), dtype=float32, numpy=0.69457614>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6819954>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70943373>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7465631>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7614266>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7393204>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7462926>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72693795>, <tf.Tensor: shape=(), dtype=float32, numpy=0.69470346>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.68294483>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6660871>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6594762>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6657097>, <tf.Tensor: shape=(), dtype=float32, numpy=0.66902876>, <tf.Tensor: shape=(), dtype=float32, numpy=0.66983336>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6789346>]\n",
      "cleint: 0 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.701369>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72298807>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7390199>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7331773>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7372293>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7384572>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7306239>]\n",
      "cleint: 6 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.713865>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75901634>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7734025>, <tf.Tensor: shape=(), dtype=float32, numpy=0.719786>, <tf.Tensor: shape=(), dtype=float32, numpy=0.70966566>, <tf.Tensor: shape=(), dtype=float32, numpy=0.69890887>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6645183>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70907784>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7474029>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7699877>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7535939>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7465267>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7535017>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7338757>]\n",
      "cleint: 8 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.70754814>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7411814>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7612294>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7542907>, <tf.Tensor: shape=(), dtype=float32, numpy=0.751228>, <tf.Tensor: shape=(), dtype=float32, numpy=0.747717>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7260158>]\n",
      "cleint: 20 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7121571>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75333935>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7757112>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75179726>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75111187>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75277245>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7238168>]\n",
      "cleint: 3 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.71419823>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7585523>, <tf.Tensor: shape=(), dtype=float32, numpy=0.77847695>, <tf.Tensor: shape=(), dtype=float32, numpy=0.73532194>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7402101>, <tf.Tensor: shape=(), dtype=float32, numpy=0.72775984>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6819713>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.69888693>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7128699>, <tf.Tensor: shape=(), dtype=float32, numpy=0.720524>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7098788>, <tf.Tensor: shape=(), dtype=float32, numpy=0.71105576>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7085297>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7014113>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.6864988>, <tf.Tensor: shape=(), dtype=float32, numpy=0.677989>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6753171>, <tf.Tensor: shape=(), dtype=float32, numpy=0.67873764>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6781917>, <tf.Tensor: shape=(), dtype=float32, numpy=0.67948866>, <tf.Tensor: shape=(), dtype=float32, numpy=0.69076043>]\n",
      "cleint: 2 is overfitting - Apply Aggresive\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7067927>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7385066>, <tf.Tensor: shape=(), dtype=float32, numpy=0.757506>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7415626>, <tf.Tensor: shape=(), dtype=float32, numpy=0.73193294>, <tf.Tensor: shape=(), dtype=float32, numpy=0.73629504>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7138347>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7064629>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7376922>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7502136>, <tf.Tensor: shape=(), dtype=float32, numpy=0.717383>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7158809>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7082265>, <tf.Tensor: shape=(), dtype=float32, numpy=0.67957085>]\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.71426535>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7599767>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7825958>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7534451>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7486205>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7419897>, <tf.Tensor: shape=(), dtype=float32, numpy=0.6987355>]\n",
      "INFO:tensorflow:Assets written to: ./models/Embryo-R300-E1-B16-OverSampling-Aggresive-DA/R-7/assets\n",
      "Loss curve points: [<tf.Tensor: shape=(), dtype=float32, numpy=0.7118388>, <tf.Tensor: shape=(), dtype=float32, numpy=0.75226825>, <tf.Tensor: shape=(), dtype=float32, numpy=0.77034885>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7428742>, <tf.Tensor: shape=(), dtype=float32, numpy=0.7396205>, <tf.Tensor: shape=(), dtype=float32, numpy=0.73521113>, <tf.Tensor: shape=(), dtype=float32, numpy=0.69942385>]\n",
      "DEBUG flower 2022-06-02 11:28:28,688 | server.py:167 | evaluate_round received 29 results and 0 failures\n",
      "Current time 131.48217225074768\n",
      "Server Metric aggregation 7==300\n",
      "DEBUG flower 2022-06-02 11:28:28,689 | server.py:198 | fit_round: strategy sampled 29 clients (out of 29)\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loopStarting custom training loop\n",
      "\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n"
     ]
    }
   ],
   "source": [
    "!python3 'vitrolife_federated_dynamic_augment.py' --ExperimentName=\"Embryo-R300-E1-B16-OverSampling-Aggresive-DA\" \\\n",
    "                                    --NumberOfClients=23 \\\n",
    "                                    --FractionOfClients=1 \\\n",
    "                                    --NumberOfRounds=300 \\\n",
    "                                    --BalancingStrategy=\"OverSampling\" \\\n",
    "                                    --DataAugmentation=\"True\" \\\n",
    "                                    --BatchSize=16 \\\n",
    "                                    --NumberOfEpochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2cb48-0d57-449d-81a8-7f86d025f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_axis = [0,1,2,3,4,5,6,7,8,9]\n",
    "y_loss [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "line_regress_result = linregress(np.array(x_axis), np.array(y_loss))\n",
    "slope = line_regress_result.slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c30c3c-3eb0-44a7-bf5b-1e251a1a66e8",
   "metadata": {},
   "source": [
    "### Load final model and apply test set \"federated eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2581072c-d79e-401c-8b18-8805a49d209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import client.vitrolife.vitrolife_client as Client\n",
    "import server.vitrolife.vitrolife_server as Server\n",
    "\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "import utils.dataloaders.vitrolife_dataloader as DataLoader\n",
    "import utils.models.vitrolife_model as Model\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    batz_size = 32\n",
    "    balancing_strategy = \"None\"\n",
    "    training_loader = DataLoader.VitroLifeDataloader(\"/mnt/data/vitroLifeDataset\", batz_size , dataset_split=\"Train\", data_augmentation = \"False\", balancing_strategy=balancing_strategy, clinic_ID=i)\n",
    "    validation_loader =  DataLoader.VitroLifeDataloader(\"/mnt/data/vitroLifeDataset\", batz_size , dataset_split=\"Validation\", data_augmentation = \"False\", balancing_strategy=balancing_strategy, clinic_ID=i)\n",
    "    testing_loader = DataLoader.VitroLifeDataloader(\"/mnt/data/vitroLifeDataset\", batz_size , dataset_split=\"Test\", data_augmentation = \"False\", balancing_strategy=balancing_strategy, clinic_ID=i)\n",
    "\n",
    "    print(f\"training count client-{i}: {training_loader.count()}\")\n",
    "    print(f\"validation count client-{i}: {validation_loader.count()}\")\n",
    "    print(f\"test count client-{i}:{testing_loader.count()}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
