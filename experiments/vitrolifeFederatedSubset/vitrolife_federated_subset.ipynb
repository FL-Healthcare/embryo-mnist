{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f479bb17-c2da-496e-b767-7aadad74f3e5",
   "metadata": {},
   "source": [
    "### Options:\n",
    "* NumberOfClients = 1-23\n",
    "    * *Client processes that the simulation starts*\n",
    "* FractionOfClients = [0,1]  \n",
    "    * *Percentage of clients perticipating each training round for fit/eval*\n",
    "* NumberOfRounds = 1-*\n",
    "    * *Numbers of federated rounds*\n",
    "* BalancingStrategy = 'OverSampling'/'ClassWeights'/'None'\n",
    "    * *Compensate for dataset class imbalance*\n",
    "* DataAugmentation = 'True'/'False'\n",
    "    * *To augment data sample while training, to avoid overfit*\n",
    "* BatchSize = 16/32/64/128\n",
    "    * *Size of each batch getting fed to the network*\n",
    "* NumberOfEpochs = 1-*\n",
    "    * *Number of local epochs on clients*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970de7ee-45e2-4805-8eb6-8495250279dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 'vitrolife_federated.py' --ExperimentName=\"Embryo-R10-E5-B64-ClassWeights-DA-ALL\" \\\n",
    "                                    --NumberOfClients=23 \\\n",
    "                                    --FractionOfClients=1 \\\n",
    "                                    --NumberOfRounds=10 \\\n",
    "                                    --BalancingStrategy=\"ClassWeights\" \\\n",
    "                                    --DataAugmentation=\"True\" \\\n",
    "                                    --BatchSize=64 \\\n",
    "                                    --NumberOfEpochs=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c30c3c-3eb0-44a7-bf5b-1e251a1a66e8",
   "metadata": {},
   "source": [
    "### Load final model and apply test set \"federated eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e40b313-6e31-4c93-b730-13e58c1e011c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14144de5-c6ff-47c3-8c10-bf74370a2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import client.vitrolife.vitrolife_client as Client\n",
    "import server.vitrolife.vitrolife_server as Server\n",
    "\n",
    "list_train = []\n",
    "for i in range(23):\n",
    "\n",
    "    client = Client.VitrolifeClient(i, 5, 2, \"test\",  balancing_strategy=\"OverSampling\", use_data_augmentor=\"False\", batch_size=32)\n",
    "    \n",
    "    training_data = client.training_generator.__len__()\n",
    "    \n",
    "    #client.evaluate(None, None)\n",
    "    list_train.append((training_data, f\"client.-{i}\"))\n",
    "\n",
    "\n",
    "list_train.sort()\n",
    "print(list_train)\n",
    "#result = client.evaluate(None, None)\n",
    "\n",
    "#print(result)\n",
    "#model = client.model\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563063c0-aff8-49bf-8724-94f1b70b2bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "#print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1995c768-bf08-4bb2-ae38-33726e11a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from numpy import save\n",
    "from numpy import asarray\n",
    "from numpy import load\n",
    "\n",
    "import random as random\n",
    "import time\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import logging\n",
    "\n",
    "def eval_metrics_aggregate(result):\n",
    "    print(\"Server Last round metrics aggregation\")\n",
    "    fullpath = \"/mnt/data/FederatedLearning/client/vitrolife/clientLogs\"\n",
    "\n",
    "    ground_truths = []\n",
    "    predicted = []\n",
    "\n",
    "    ground_truths_matrix = []\n",
    "    predicted_matrix = []\n",
    "\n",
    "    for client_id in range(23):\n",
    "        current_predicted = load(f\"{fullpath}/predicted_{client_id}.npy\")\n",
    "        current_ground = load(f\"{fullpath}/ground_{client_id}.npy\")\n",
    "        print(\"Loading done\")\n",
    "\n",
    "        # Be aware of max sampling warning\n",
    "        current_ground = current_ground.tolist()\n",
    "        current_predicted = current_predicted.tolist()\n",
    "\n",
    "\n",
    "        ground_truths_matrix.extend(current_ground)\n",
    "        predicted_matrix.extend(current_predicted)\n",
    "\n",
    "        ground_truths.extend(current_ground)\n",
    "        predicted.extend(current_predicted)               \n",
    "\n",
    "    predicted_arg_max = []\n",
    "    predicted_probabilities_transformed = []\n",
    "\n",
    "    for proba in predicted:\n",
    "        proba = proba[0]\n",
    "        predicted_probabilities_transformed.append([1-proba, proba])\n",
    "        if proba > 0.5:\n",
    "            predicted_arg_max.append(1)\n",
    "        else:\n",
    "            predicted_arg_max.append(0)\n",
    "\n",
    "    predicted_arg_max = [proba.index(max(proba)) for proba in predicted_matrix]\n",
    "    classes = ['No Pregnancy', 'Pregnancy']       \n",
    "\n",
    "    wandb.sklearn.plot_confusion_matrix(ground_truths, predicted_arg_max, labels=classes)\n",
    "    wandb.log({\"roc\" : wandb.plot.roc_curve(ground_truths, predicted_probabilities_transformed, labels=classes)})\n",
    "\n",
    "    # wait for confustion to finsih\n",
    "    time.sleep(10)\n",
    "    wandb.finish()\n",
    "                \n",
    "        \n",
    "        \n",
    "experiment_name = \"TestPeter\"\n",
    "wandb.init(project=experiment_name, entity=\"anton-peter\")\n",
    "wandb.run.name = f\"Vitrolife Aggregation-Server\"\n",
    "eval_metrics_aggregate(None)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2581072c-d79e-401c-8b18-8805a49d209b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 1, 17, 5, 2, 4, 8, 18, 12, 3]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import client.vitrolife.vitrolife_client as Client\n",
    "import server.vitrolife.vitrolife_server as Server\n",
    "\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "import utils.dataloaders.vitrolife_dataloader as DataLoader\n",
    "import utils.models.vitrolife_model as Model\n",
    "\n",
    "\n",
    "client_training_sizes = []\n",
    "number_of_clients = 23\n",
    "for client_id in range(number_of_clients):\n",
    "    batch_size = 16\n",
    "    balancing_strategy = \"None\"\n",
    "    training_loader = DataLoader.VitroLifeDataloader(\"/mnt/data/vitroLifeDataset\", batch_size , dataset_split=\"Train\", data_augmentation = \"False\", balancing_strategy=balancing_strategy,clinic_ID=client_id )\n",
    "    \n",
    "    current_training_count = training_loader.count()\n",
    "    \n",
    "    client_training_sizes.append((current_training_count, client_id))\n",
    "\n",
    "\n",
    "client_training_sizes.sort(reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print([item[1] for item in client_training_sizes[0:10]])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a8c52-fbc3-4cc3-aca2-c1c08eb79925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../..')\n",
    "import utils.dataloaders.auto_flush as AutoFlush\n",
    "import utils.dataloaders.vitrolife_dataloader_old as DataLoader\n",
    "import utils.models.vitrolife_model as ModelLort\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Reshape\n",
    "from keras.models import Model\n",
    "\n",
    "METRICS = [\n",
    "    keras.metrics.TruePositives(name='tp'),\n",
    "    keras.metrics.FalsePositives(name='fp'),\n",
    "    keras.metrics.TrueNegatives(name='tn'),\n",
    "    keras.metrics.FalseNegatives(name='fn'), \n",
    "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(from_logits=True),\n",
    "    keras.metrics.AUC(name='prc', curve='PR', from_logits=True), # precision-recall curve\n",
    "]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), input_shape=(250,250,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256)) # W1*x + b\n",
    "model.add(Activation('relu')) # ReLU(W1*x + b)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1)) # W2*x + b\n",
    "model.add(Activation('sigmoid'))  # softmax(W2*x + b)\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.000001, decay=1e-6)\n",
    "\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=opt,\n",
    "              metrics=METRICS)\n",
    "        \n",
    "\n",
    "import resource\n",
    "class MemoryCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, log={}):\n",
    "        print(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "        \n",
    "batch_size = 32        \n",
    "training_generator = DataLoader.VitroLifeDataloader(\"/mnt/data/vitroLifeDataset\", batch_size , dataset_split=\"Train\", data_augmentation =\"False\" , balancing_strategy=\"None\", clinic_ID=0)\n",
    "validation_generator = DataLoader.VitroLifeDataloader(\"/mnt/data/vitroLifeDataset\", batch_size , dataset_split=\"Validation\", clinic_ID=0)\n",
    "\n",
    "model_gen = ModelLort.VitroLifeModel()\n",
    "model_from_gen = model_gen.get_low_GPU_mem_model() \n",
    "# ...\n",
    "#X_train = np.random.rand(5000, 250, 250, 1)\n",
    "#Y_train = np.random.randint(0, 2, size=5000)\n",
    "#X_test = np.random.rand(5000, 250, 250, 1)\n",
    "#Y_test = np.random.randint(0, 2, size=5000)\n",
    "\n",
    "list_x = []\n",
    "list_y = []\n",
    "for batches in range(training_generator.__len__()):\n",
    "    x, y = training_generator.__getitem__(batches)\n",
    "    #x, y = training_generator.__getitem__(batches)\n",
    "    list_x.extend(x)\n",
    "    list_y.extend(y)\n",
    "\n",
    "list_x = np.array(list_x) \n",
    "list_y = np.array(list_y) \n",
    "\n",
    "\n",
    "model_from_gen.fit(list_x, list_y, epochs=500, callbacks=[MemoryCallback()], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aedd0c-d7ad-4abd-97e0-55bcef2337ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(list_x, list_y, epochs=500, callbacks=[MemoryCallback(), AutoFlush.FlushCallback()], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e05433b-013d-4eed-b094-6eb361dcea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import client.vitrolife.vitrolife_client as Client\n",
    "\n",
    "\n",
    "client = Client.VitrolifeClient(0, 10, 10, \"test\", \"None\", \"false\", 32)\n",
    "\n",
    "lort = client.fit(None, None)\n",
    "\n",
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "\n",
    "client = Client.VitrolifeClient(0, 10, 10, \"test\", \"None\", \"false\", 32)\n",
    "\n",
    "lort = client.fit(None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8167ae8-956e-492c-baf1-5f0e7efc9fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ac5d7-ed0e-4815-a35b-cdf0db01040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow-text==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c23d29d-679c-4656-a2d3-d81e2f7a8bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71e9b26-3a0e-45f5-a095-3e466e30f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea52891c-834d-4018-871b-e3da0d8713c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from tensorflow import keras\n",
    "import numpy\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "\n",
    "# 0.0000001\n",
    "#model_name = \"Embryo-Centralized-B16-E100-No-LrSchedule/Epoch-97\"\n",
    "model_name = \"Embryo-Federated-B16-R100-E1-OverSampling/R-3\"\n",
    "model_from_disk = keras.models.load_model(f\"models/{model_name}\")\n",
    "print(K.eval(model_from_disk.optimizer.lr))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
