{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f479bb17-c2da-496e-b767-7aadad74f3e5",
   "metadata": {},
   "source": [
    "### Options:\n",
    "* NumberOfClients = 1-23\n",
    "    * *Client processes that the simulation starts*\n",
    "* FractionOfClients = [0,1]  \n",
    "    * *Percentage of clients perticipating each training round for fit/eval*\n",
    "* NumberOfRounds = 1-*\n",
    "    * *Numbers of federated rounds*\n",
    "* BalancingStrategy = 'OverSampling'/'ClassWeights'/'None'\n",
    "    * *Compensate for dataset class imbalance*\n",
    "* DataAugmentation = 'True'/'False'\n",
    "    * *To augment data sample while training, to avoid overfit*\n",
    "* BatchSize = 16/32/64/128\n",
    "    * *Size of each batch getting fed to the network*\n",
    "* NumberOfEpochs = 1-*\n",
    "    * *Number of local epochs on clients*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "970de7ee-45e2-4805-8eb6-8495250279dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 13:41:44.787625: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:41:44.896027: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "-n Embryo-R3-E1-B16-OverSampling-DA-QFed -c 23 -f 1.0 -r 3 -bs OverSampling -d True -b 16 -e 1\n",
      "Init server\n",
      "Number of rounds 3, fraction fit/eval 1.0, experiment name Embryo-R3-E1-B16-OverSampling-DA-QFed\n",
      "2022-05-30 13:41:50.134806: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:41:50.487704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22319 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "INFO flower 2022-05-30 13:41:50,667 | app.py:109 | Flower server running (3 rounds), SSL is disabled\n",
      "INFO flower 2022-05-30 13:41:50,667 | server.py:84 | Initializing global parameters\n",
      "INFO flower 2022-05-30 13:41:50,668 | server.py:249 | Requesting initial parameters from one random client\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-peter\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "2022-05-30 13:42:01.815352: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:01.829722: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:01.857370: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:01.881814: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:01.886076: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:01.900060: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:01.919325: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:01.939221: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:01.948286: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-30 13:42:01.948385: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-30 13:42:01.949647: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:01.954956: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:01.966355: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:01.982484: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-30 13:42:01.992782: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:01.994647: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:01.997529: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-30 13:42:01.997530: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-30 13:42:02.012333: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-30 13:42:02.025412: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:02.030269: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:02.041932: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-30 13:42:02.045077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:02.059803: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-30 13:42:02.063577: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:02.065022: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-30 13:42:02.082423: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-30 13:42:02.082841: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:02.093738: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-30 13:42:02.104193: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:02.109824: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-30 13:42:02.110489: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:02.117017: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-30 13:42:02.128224: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:02.138030: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:02.146829: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-30 13:42:02.146833: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-30 13:42:02.155108: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "2022-05-30 13:42:02.186954: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-30 13:42:02.194061: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "2022-05-30 13:42:02.197259: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "2022-05-30 13:42:02.247324: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "2022-05-30 13:42:02.250325: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "2022-05-30 13:42:02.269733: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "2022-05-30 13:42:02.289515: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "2022-05-30 13:42:02.311714: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-2keepqad\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-2im4u4mk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-3vg260f7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mearthy-paper-3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/2keepqad\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwarm-valley-5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/2im4u4mk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myoung-elevator-6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/3vg260f7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-1h6n21bc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mazure-silence-4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/1h6n21bc\u001b[0m\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Using oversampler strategy in dataloader\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Using data augmentation\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Client 4 is using GPU\n",
      "Client 3 is using GPU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-28xea9nk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mproud-sound-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/28xea9nk\u001b[0m\n",
      "Client 21 is using CPU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-1ojgs85s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdevout-fire-12\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/1ojgs85s\u001b[0m\n",
      "Using oversampler strategy in dataloader\n",
      "Client 20 is using GPU\n",
      "Using data augmentation\n",
      "2022-05-30 13:42:03.638867: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-c3dq8k8s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdecent-valley-9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/c3dq8k8s\u001b[0m\n",
      "Client 2 is using GPU\n",
      "Client 10 is using CPU\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-18ier9zn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mchocolate-planet-10\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/18ier9zn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-3io98kxj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msuper-serenity-7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/3io98kxj\u001b[0m\n",
      "Client 1 is using GPU\n",
      "2022-05-30 13:42:03.714886: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Using oversampler strategy in dataloader\n",
      "Using oversampler strategy in dataloader\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-3jeuvgju\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "Using data augmentation\n",
      "Using data augmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrural-sunset-13\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/3jeuvgju\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-3k8pgfhq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlogical-leaf-15\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/3k8pgfhq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-2p3ivk51\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdark-capybara-8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/2p3ivk51\u001b[0m\n",
      "Client 5 is using GPU\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-2e2vi5bf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mclean-smoke-20\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/2e2vi5bf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "Client 12 is using GPU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-2l2ffqsp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "Client 15 is using CPU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mzesty-glade-2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/2l2ffqsp\u001b[0m\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "New model directory is created\n",
      "Client 11 is using CPU\n",
      "Client 19 is using CPU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-31e932fe\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mserene-river-19\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/31e932fe\u001b[0m\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "2022-05-30 13:42:03.841069: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-1eijnywx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mswept-river-18\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/1eijnywx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-2tdskdd7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-26quxdzu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfloral-eon-11\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/2tdskdd7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvaliant-wood-16\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/26quxdzu\u001b[0m\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-1j3n0vuq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtoasty-microwave-22\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/1j3n0vuq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-05-30 13:42:03.861704: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-1ejvdbn9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "2022-05-30 13:42:03.861937: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrobust-galaxy-14\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/1ejvdbn9\u001b[0m\n",
      "Client 0 is using CPU\n",
      "Using oversampler strategy in dataloader\n",
      "Using oversampler strategy in dataloader\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Client 6 is using CPU\n",
      "Using data augmentation\n",
      "Using data augmentation\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "INFO flower 2022-05-30 13:42:03,921 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:03,922 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:03,922 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:03,923 | connection.py:39 | ChannelConnectivity.READY\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "Client 13 is using CPU\n",
      "Client 9 is using CPU\n",
      "Client 16 is using CPU\n",
      "2022-05-30 13:42:03.913539: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:03.923135: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Client 22 is using CPU\n",
      "INFO flower 2022-05-30 13:42:03,961 | server.py:252 | Received initial parameters from one random client\n",
      "INFO flower 2022-05-30 13:42:03,961 | server.py:86 | Evaluating initial parameters\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-3lvl5fzi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgood-oath-17\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/3lvl5fzi\u001b[0m\n",
      "2022-05-30 13:42:03.942051: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:03.943079: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:03.945612: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:03.957645: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Client 18 is using GPU\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "INFO flower 2022-05-30 13:42:04,018 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,019 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,020 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,020 | connection.py:39 | ChannelConnectivity.READY\n",
      "Client 17 is using GPU\n",
      "Client 14 is using CPU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-3jm2dueq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstilted-leaf-21\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/3jm2dueq\u001b[0m\n",
      "2022-05-30 13:42:04.051567: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "INFO flower 2022-05-30 13:42:04,129 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,130 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "Client 7 is using GPU\n",
      "DEBUG flower 2022-05-30 13:42:04,130 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,131 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-05-30 13:42:04,150 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,151 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,151 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,152 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-05-30 13:42:04,174 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "INFO flower 2022-05-30 13:42:04,174 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,175 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "INFO flower 2022-05-30 13:42:04,175 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,175 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,175 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,175 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,176 | connection.py:39 | ChannelConnectivity.READY\n",
      "DEBUG flower 2022-05-30 13:42:04,176 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,176 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,189 | connection.py:39 | ChannelConnectivity.READY\n",
      "DEBUG flower 2022-05-30 13:42:04,189 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-05-30 13:42:04,205 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,206 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "INFO flower 2022-05-30 13:42:04,208 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,208 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "INFO flower 2022-05-30 13:42:04,209 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,209 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,210 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,210 | connection.py:39 | ChannelConnectivity.READY\n",
      "DEBUG flower 2022-05-30 13:42:04,210 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "INFO flower 2022-05-30 13:42:04,210 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,211 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,212 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,213 | connection.py:39 | ChannelConnectivity.READY\n",
      "DEBUG flower 2022-05-30 13:42:04,213 | connection.py:39 | ChannelConnectivity.READY\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/data/FederatedLearning/experiments/VitrolifeQFed/wandb/run-20220530_134200-2qffa3cw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mleafy-disco-23\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/2qffa3cw\u001b[0m\n",
      "2022-05-30 13:42:03.606603: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "DEBUG flower 2022-05-30 13:42:04,255 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,257 | connection.py:39 | ChannelConnectivity.READY\n",
      "2022-05-30 13:42:03.606443: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:04.261845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18725 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "Using oversampler strategy in dataloader\n",
      "Using data augmentation\n",
      "2022-05-30 13:42:04.240767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18793 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2022-05-30 13:42:03.699003: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Client 8 is using GPU\n",
      "2022-05-30 13:42:03.659942: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:04.267192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18721 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2022-05-30 13:42:04.282961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18665 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2022-05-30 13:42:03.751272: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO flower 2022-05-30 13:42:04,358 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,360 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,360 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,361 | connection.py:39 | ChannelConnectivity.READY\n",
      "2022-05-30 13:42:04.340299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18526 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2022-05-30 13:42:03.793286: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:04.403207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18148 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "INFO flower 2022-05-30 13:42:04,469 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,472 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,472 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-05-30 13:42:04,489 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "2022-05-30 13:42:03.841604: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "DEBUG flower 2022-05-30 13:42:04,491 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,491 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,492 | connection.py:39 | ChannelConnectivity.READY\n",
      "2022-05-30 13:42:04.468173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 17974 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "INFO flower 2022-05-30 13:42:04,512 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,513 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,514 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,514 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-05-30 13:42:04,515 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,516 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,516 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,516 | connection.py:39 | ChannelConnectivity.READY\n",
      "2022-05-30 13:42:03.994994: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:04.039775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:04.543721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 17816 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "INFO flower 2022-05-30 13:42:04,572 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,573 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,574 | connection.py:39 | ChannelConnectivity.READY\n",
      "2022-05-30 13:42:04.138374: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:04.560303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 17788 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2022-05-30 13:42:04.587382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 17756 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "INFO flower 2022-05-30 13:42:04,626 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,627 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,628 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,629 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-05-30 13:42:04,662 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,663 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,663 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,664 | connection.py:39 | ChannelConnectivity.READY\n",
      "2022-05-30 13:42:04.297917: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 13:42:04.705615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 17658 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "INFO flower 2022-05-30 13:42:04,736 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,737 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,737 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-05-30 13:42:04,753 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,754 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,755 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,755 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-05-30 13:42:04,784 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,785 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,823 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,824 | connection.py:39 | ChannelConnectivity.READY\n",
      "INFO flower 2022-05-30 13:42:04,907 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flower 2022-05-30 13:42:04,908 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2022-05-30 13:42:04,944 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flower 2022-05-30 13:42:04,971 | connection.py:39 | ChannelConnectivity.READY\n",
      "2022-05-30 13:42:05.705980: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-05-30 13:42:06.587458: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-05-30 13:42:06.784525: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "207/207 [==============================] - 32s 142ms/step - loss: 0.6915 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 2205.0000 - fn: 1107.0000 - accuracy: 0.6658 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.3342\n",
      "INFO flower 2022-05-30 13:42:36,128 | server.py:89 | initial parameters (loss, other metrics): 0.6914828419685364, {'auc': 0.5}\n",
      "INFO flower 2022-05-30 13:42:36,128 | server.py:99 | FL starting\n",
      "DEBUG flower 2022-05-30 13:42:36,141 | server.py:198 | fit_round: strategy sampled 23 clients (out of 23)\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "2022-05-30 13:42:39.156170: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-05-30 13:42:39.361024: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-05-30 13:42:39.469526: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-05-30 13:42:39.489079: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-05-30 13:42:39.653669: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-05-30 13:42:39.883682: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-05-30 13:42:39.958931: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-05-30 13:42:40.031008: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-05-30 13:42:40.196555: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-05-30 13:42:40.299478: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-05-30 13:42:40.360087: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-05-30 13:42:44.356077: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-05-30 13:42:44.826317: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-05-30 13:42:45.054276: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-05-30 13:42:45.303531: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-05-30 13:42:45.305729: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-05-30 13:42:45.374812: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-05-30 13:42:45.389132: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-05-30 13:42:45.405375: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-05-30 13:42:45.438643: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-05-30 13:42:45.460205: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-05-30 13:42:45.465466: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-05-30 13:42:45.468118: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-05-30 13:42:45.514610: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-05-30 13:42:45.759535: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-05-30 13:42:45.769970: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-05-30 13:42:45.780165: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-05-30 13:42:45.833420: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-05-30 13:42:45.858532: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-05-30 13:42:45.895135: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-05-30 13:42:45.924736: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-05-30 13:42:45.925093: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-05-30 13:42:45.994475: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "DEBUG flower 2022-05-30 13:44:41,758 | server.py:210 | fit_round received 23 results and 0 failures\n",
      "207/207 [==============================] - 30s 142ms/step - loss: 0.6915 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 2201.0000 - fn: 1111.0000 - accuracy: 0.6646 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.3354\n",
      "WARNING flower 2022-05-30 13:45:11,946 | qfedavg.py:231 | No fit_metrics_aggregation_fn provided\n",
      "207/207 [==============================] - 29s 141ms/step - loss: 0.6914 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 2204.0000 - fn: 1108.0000 - accuracy: 0.6655 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.3345\n",
      "INFO flower 2022-05-30 13:45:41,532 | server.py:114 | fit progress: (1, 0.6914170980453491, {'auc': 0.5}, 185.4037864790298)\n",
      "DEBUG flower 2022-05-30 13:45:41,532 | server.py:155 | evaluate_round: strategy sampled 23 clients (out of 23)\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.trackable_utils has been moved to tensorflow.python.trackable.trackable_utils. The old module will be deleted in version 2.11.\n",
      "INFO:tensorflow:Assets written to: ./models/Embryo-R3-E1-B16-OverSampling-DA-QFed/R-1/assets\n",
      "DEBUG flower 2022-05-30 13:45:50,468 | server.py:167 | evaluate_round received 23 results and 0 failures\n",
      "WARNING flower 2022-05-30 13:45:50,468 | qfedavg.py:262 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flower 2022-05-30 13:45:50,489 | server.py:198 | fit_round: strategy sampled 23 clients (out of 23)\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "DEBUG flower 2022-05-30 13:47:51,192 | server.py:210 | fit_round received 23 results and 0 failures\n",
      "207/207 [==============================] - 30s 142ms/step - loss: 0.6914 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 2205.0000 - fn: 1107.0000 - accuracy: 0.6658 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.3342\n",
      "207/207 [==============================] - 29s 141ms/step - loss: 0.6914 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 2206.0000 - fn: 1106.0000 - accuracy: 0.6661 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.3339\n",
      "INFO flower 2022-05-30 13:48:50,956 | server.py:114 | fit progress: (2, 0.6914005279541016, {'auc': 0.5}, 374.8278139199829)\n",
      "DEBUG flower 2022-05-30 13:48:50,956 | server.py:155 | evaluate_round: strategy sampled 23 clients (out of 23)\n",
      "INFO:tensorflow:Assets written to: ./models/Embryo-R3-E1-B16-OverSampling-DA-QFed/R-2/assets\n",
      "DEBUG flower 2022-05-30 13:48:59,366 | server.py:167 | evaluate_round received 23 results and 0 failures\n",
      "DEBUG flower 2022-05-30 13:48:59,388 | server.py:198 | fit_round: strategy sampled 23 clients (out of 23)\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "Starting custom training loop\n",
      "DEBUG flower 2022-05-30 13:51:00,697 | server.py:210 | fit_round received 23 results and 0 failures\n",
      "207/207 [==============================] - 30s 142ms/step - loss: 0.6914 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 2202.0000 - fn: 1110.0000 - accuracy: 0.6649 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.3351\n",
      "207/207 [==============================] - 30s 143ms/step - loss: 0.6914 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 2202.0000 - fn: 1110.0000 - accuracy: 0.6649 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.3351\n",
      "INFO flower 2022-05-30 13:52:01,202 | server.py:114 | fit progress: (3, 0.6914356350898743, {'auc': 0.5}, 565.0738385380246)\n",
      "DEBUG flower 2022-05-30 13:52:01,203 | server.py:155 | evaluate_round: strategy sampled 23 clients (out of 23)\n",
      "Eval final model - client 16\n",
      "Eval final model - client 9\n",
      "Eval final model - client 21\n",
      "Eval final model - client 19\n",
      "Eval final model - client 13\n",
      "Eval final model - client 22\n",
      "Eval final model - client 11\n",
      "Eval final model - client 10\n",
      "Eval final model - client 14\n",
      "Eval final model - client 15\n",
      "Eval final model - client 0\n",
      "Eval final model - client 6\n",
      "Eval final model - client 3\n",
      "Eval final model - client 8\n",
      "Eval final model - client 20\n",
      "Eval final model - client 12\n",
      "Eval final model - client 18\n",
      "Eval final model - client 4\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "Eval final model - client 2\n",
      "Eval final model - client 5 MB of 0.001 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "Eval final model - client 17MB of 0.001 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.007 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "INFO:tensorflow:Assets written to: ./models/Embryo-R3-E1-B16-OverSampling-DA-QFed/R-3/assets\n",
      "Eval final model - client 1 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "Eval final model - client 7 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss ▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy ▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn █▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp █▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss █▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc ▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision ▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall ▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn ▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp ▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss ▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.5625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.5754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.6924\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.52315\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.54112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 109.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 97.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.80049\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.54266\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.52217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.49302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 120.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 106.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.4375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.53373\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 36.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.69501\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.45864\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.4375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 28.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdevout-fire-12\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/1ojgs85s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-1ojgs85s/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss █▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy █▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc █▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn ▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp █▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss ▁█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc █▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision █▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall █▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn ▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp █▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.52083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69049\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.49821\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.49284\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 150.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 131.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.85205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.48216\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.49615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.46237\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 150.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 129.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.44643\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 56.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.69859\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.26104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 24.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc █▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss ▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy ▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc █▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn ▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp █▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss ▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc ▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision ▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall ▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn ▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp ▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss ▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.40625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.50101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69441\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.51157\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.52632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 217.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 205.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.80886\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.5393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.51537\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.50115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 224.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 218.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.59375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.52845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 78.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.69158\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.62583\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.59375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 114.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc █▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss ▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy ▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc ▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn ▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp ▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss █▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc ▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision ▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall █▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn ▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp █▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss █▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.58333\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.68987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.57701\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.60134\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 212.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 167.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.74762\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.62516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.58458\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.52573\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 282.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 235.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.53646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 32.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.67729\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.26446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 96.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc ▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss ▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy ▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc ▇▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp ▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss ▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc █▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision ▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn ▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss ▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.66827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.51817\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.52518\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 334.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 329.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.78008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.51156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.5183\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.51453\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 359.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 354.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.33173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.56881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 139.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.70565\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.42011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.33173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 69.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc ▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss ▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc ██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn ▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp █▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss ▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall ▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn ▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp ▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc █▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss █▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▇▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.67188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.52852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.51322\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.50046\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 198.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 207.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.81881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.51218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.51408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.52518\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 208.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 219.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.67188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.51855\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 42.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.68713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.35397\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 86.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc ▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss ▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy █▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc █▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp ▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss ▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc █▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision █▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn █▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc █▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn ▇█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss ▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▇▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ▇▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn ▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.70312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.45351\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.51119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.50717\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 257.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 267.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.81534\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.50857\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.51009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.51963\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 270.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 278.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.29688\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.56842\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 90.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.69758\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.35439\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.29688\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 38.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss █▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy ▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc ▁█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn █▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss █▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc ▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision ▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall ▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp ▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss █▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69201\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.35565\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 17.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 7.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 1.12738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.40374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.46154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.26087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 18.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 6.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.69386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 6.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss ▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc █▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn ▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss ▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc ▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall █▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp █▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn ▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.69231\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.56944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69073\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.51562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.4873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 21.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 1.01054\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.50614\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.52381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.34375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 22.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 11.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.23077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 9.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.69416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.30769\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 3.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc ██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss █▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy ▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc ▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn █▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss █▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc ▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision ▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall ▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn █▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp ▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc █▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss █▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc █▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.35417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.47676\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.6947\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.43519\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.43351\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 125.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 119.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.91822\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.44778\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.42788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.41589\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 99.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 89.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.35417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.47225\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 62.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.69714\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.61524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 34.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc █▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss ▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy ▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc ▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn █▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp █▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss █▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc ▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision ▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall ▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn ▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp ▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss ▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc █▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.76562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.45408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69062\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.5464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.56336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 235.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 244.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.77452\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.54726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.54647\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.55577\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 283.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 294.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.23438\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.49269\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 98.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.70051\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.22935\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.23438\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 30.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy ▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc ▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn █▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp ▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss █▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc █▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision ▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall ▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn ▇█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp ▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy █▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn █▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss ▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.5625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.4515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69277\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.49671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.49755\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 233.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 226.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.83161\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.50064\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.49554\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.48791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 231.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 222.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.47222\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.49559\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 7.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 69.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.69342\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.43403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 0.88889\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 12.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 56.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss ▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy ▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc █▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn ▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp ██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss ▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc █▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision ▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall █▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn ▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp █▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss ▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.53333\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.47874\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 25.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 13.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.92804\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.49388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.55172\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.39024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 26.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 6.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.69259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlogical-leaf-15\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/3k8pgfhq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc █▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss ▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy ▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc ▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp ▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss ▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision ▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn ▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss ▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.4375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69316\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.51875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.53625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 45.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 32.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.85726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.54245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.52239\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.4375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 48.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 35.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 8.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.69338\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 8.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-3k8pgfhq/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc ▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss ▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy █▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc █▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn ▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp ▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss █▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc █▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision █▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall ▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn █▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp ▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss ▁█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.73214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.46789\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.6912\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.49877\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 206.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 210.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.84018\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.48842\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.49881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.50361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 207.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 209.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.73214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.62012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 30.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.68551\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.34357\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 82.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mrural-sunset-13\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/3jeuvgju\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss ▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy ▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc ▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn ▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp █▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc ▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision ▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall █▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn ▁█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp █▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc █▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss ▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc █▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.6875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.41818\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.46354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.48546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 56.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 47.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.92353\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.46646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.45977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.41667\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 49.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 40.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.6875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.38182\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 5.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.69198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.25444\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 11.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-3jeuvgju/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss █▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy █▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc █▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn ▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp ▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss ▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc ██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision █▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall █▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn █▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp █▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss █▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.6875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.40909\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69111\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.46354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.45638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 55.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 48.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.93391\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.45311\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.46667\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.43299\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 47.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 42.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.3125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 11.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.6965\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.3125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.3125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 5.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mproud-sound-1\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/28xea9nk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msuper-serenity-7\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/3io98kxj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-28xea9nk/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-3io98kxj/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mazure-silence-4\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/1h6n21bc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-1h6n21bc/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc ▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss █▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy █▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc ▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp ▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss ▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc ▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision █▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall █▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn █▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp █▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss ▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▁█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.57812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.49149\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69216\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.49653\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.50932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 154.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 136.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.85079\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.49617\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.4963\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.46528\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 152.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 134.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.42188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.51702\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 37.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.69575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.43068\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.42188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 27.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss █▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc ▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn ▁█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp █▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss ▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc ▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall █▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn ▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp █▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss ▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69226\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.53125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.57055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 44.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 31.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.83837\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.50959\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.53731\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.45\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 49.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 36.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.69492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.3871\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 12.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc ▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss ▇▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc █▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn ▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp ▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss ▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision █▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall █▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn █▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp █▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss █▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.59821\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.49337\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.48214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.49243\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 152.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 138.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.84849\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.49252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.4812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.45714\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 142.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 128.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.40179\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.55406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 67.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.6953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.44202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.40179\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 45.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mchocolate-planet-10\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/18ier9zn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mvaliant-wood-16\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/26quxdzu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mleafy-disco-23\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/2qffa3cw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mzesty-glade-2\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/2l2ffqsp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfloral-eon-11\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/2tdskdd7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mearthy-paper-3\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/2keepqad\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mwarm-valley-5\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/2im4u4mk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mclean-smoke-20\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/2e2vi5bf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mgood-oath-17\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/3lvl5fzi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33myoung-elevator-6\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/3vg260f7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mtoasty-microwave-22\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/1j3n0vuq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mrobust-galaxy-14\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/1ejvdbn9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdark-capybara-8\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/2p3ivk51\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-26quxdzu/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-18ier9zn/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-2l2ffqsp/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-2im4u4mk/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-2qffa3cw/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-2tdskdd7/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-3lvl5fzi/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-2e2vi5bf/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-2keepqad/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-1ejvdbn9/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-1j3n0vuq/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-2p3ivk51/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-3vg260f7/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mserene-river-19\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/31e932fe\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-31e932fe/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc █▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss █▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy █▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc ▇█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp █▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss ▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc ▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision █▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall █▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn ▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp █▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss ▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn ▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp █▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.66071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.47096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.6914\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.49958\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.49293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 612.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 581.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.78606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.49435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.49914\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.48615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 612.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 579.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.33929\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.54779\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 222.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.72214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.3717\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.33929\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 114.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mswept-river-18\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/1eijnywx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-1eijnywx/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc █▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss ▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc █▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn ▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp ▁█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss ▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc █▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall ▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn █▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp ▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc █▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp █▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss █▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc █▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision ▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn ▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.75781\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.4826\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69038\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.50706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.51527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 669.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 727.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.76894\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.50877\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.50678\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.52754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 689.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 747.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.6901\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.51269\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 77.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 42.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.65179\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.24633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.27586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 0.17204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 249.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdecent-valley-9\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/c3dq8k8s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-c3dq8k8s/logs\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc █▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss ▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall ▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy ▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc ▁█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn █▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp █▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss █▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc ▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision ▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall ▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn ▁█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp ▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc ▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc ▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn █▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp ▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    R_accuracy 0.72526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         R_auc 0.48893\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        R_loss 0.69073\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   R_presision 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      R_recall 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Round 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.54907\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           auc 0.56472\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fn 1114.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fp 1202.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 0.72698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           prc 0.54661\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     presision 0.5471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        recall 0.56586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tn 1368.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            tp 1452.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.27995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_auc 0.54411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fn 3.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_fp 550.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.73808\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_prc 0.28641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_presision 0.27441\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_recall 0.98578\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tn 7.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_tp 208.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mstilted-leaf-21\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anton-peter/Embryo-QFed/runs/3jm2dueq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220530_134200-3jm2dueq/logs\u001b[0m\n",
      "DEBUG flower 2022-05-30 13:52:23,528 | server.py:167 | evaluate_round received 23 results and 0 failures\n",
      "INFO flower 2022-05-30 13:52:23,528 | server.py:138 | FL finished in 587.3999200860271\n",
      "INFO flower 2022-05-30 13:52:23,528 | app.py:149 | app_fit: losses_distributed [(1, 0.4000000059604645), (2, 0.4000000059604645), (3, 0.4000000059604645)]\n",
      "INFO flower 2022-05-30 13:52:23,529 | app.py:150 | app_fit: metrics_distributed {}\n",
      "INFO flower 2022-05-30 13:52:23,529 | app.py:151 | app_fit: losses_centralized [(0, 0.6914828419685364), (1, 0.6914170980453491), (2, 0.6914005279541016), (3, 0.6914356350898743)]\n",
      "INFO flower 2022-05-30 13:52:23,529 | app.py:152 | app_fit: metrics_centralized {'auc': [(0, 0.5), (1, 0.5), (2, 0.5), (3, 0.5)]}\n",
      "DEBUG flower 2022-05-30 13:52:23,652 | connection.py:121 | gRPC channel closed\n",
      "INFO flower 2022-05-30 13:52:23,652 | app.py:99 | Disconnect and shut down\n",
      "DEBUG flower 2022-05-30 13:52:23,654 | connection.py:121 | gRPC channel closed\n",
      "INFO flower 2022-05-30 13:52:23,654 | app.py:99 | Disconnect and shut down\n",
      "DEBUG flower 2022-05-30 13:52:23,664 | connection.py:121 | gRPC channel closed\n",
      "INFO flower 2022-05-30 13:52:23,665 | app.py:99 | Disconnect and shut down\n",
      "DEBUG flower 2022-05-30 13:52:23,667 | connection.py:121 | gRPC channel closed\n",
      "INFO flower 2022-05-30 13:52:23,667 | app.py:99 | Disconnect and shut down\n",
      "DEBUG flower 2022-05-30 13:52:23,678 | connection.py:121 | gRPC channel closed\n",
      "INFO flower 2022-05-30 13:52:23,678 | app.py:99 | Disconnect and shut down\n",
      "DEBUG flower 2022-05-30 13:52:23,750 | connection.py:121 | gRPC channel closed\n",
      "DEBUG flower 2022-05-30 13:52:23,750 | connection.py:121 | gRPC channel closed\n",
      "DEBUG flower 2022-05-30 13:52:23,750 | connection.py:121 | gRPC channel closed\n",
      "DEBUG flower 2022-05-30 13:52:23,750 | connection.py:121 | gRPC channel closed\n",
      "DEBUG flower 2022-05-30 13:52:23,750 | connection.py:121 | gRPC channel closed\n",
      "DEBUG flower 2022-05-30 13:52:23,750 | connection.py:121 | gRPC channel closed\n",
      "DEBUG flower 2022-05-30 13:52:23,750 | connection.py:121 | gRPC channel closed\n",
      "INFO flower 2022-05-30 13:52:23,750 | app.py:99 | Disconnect and shut down\n",
      "INFO flower 2022-05-30 13:52:23,750 | app.py:99 | Disconnect and shut down\n",
      "DEBUG flower 2022-05-30 13:52:23,750 | connection.py:121 | gRPC channel closed\n",
      "DEBUG flower 2022-05-30 13:52:23,750 | connection.py:121 | gRPC channel closed\n",
      "DEBUG flower 2022-05-30 13:52:23,750 | connection.py:121 | gRPC channel closed\n",
      "DEBUG flower 2022-05-30 13:52:23,750 | connection.py:121 | gRPC channel closed\n",
      "INFO flower 2022-05-30 13:52:23,751 | app.py:99 | Disconnect and shut down\n",
      "DEBUG flower 2022-05-30 13:52:23,750 | connection.py:121 | gRPC channel closed\n",
      "DEBUG flower 2022-05-30 13:52:23,750 | connection.py:121 | gRPC channel closed\n",
      "DEBUG flower 2022-05-30 13:52:23,750 | connection.py:121 | gRPC channel closed\n",
      "DEBUG flower 2022-05-30 13:52:23,750 | connection.py:121 | gRPC channel closed\n",
      "INFO flower 2022-05-30 13:52:23,751 | app.py:99 | Disconnect and shut down\n",
      "DEBUG flower 2022-05-30 13:52:23,750 | connection.py:121 | gRPC channel closed\n",
      "INFO flower 2022-05-30 13:52:23,751 | app.py:99 | Disconnect and shut down\n",
      "INFO flower 2022-05-30 13:52:23,751 | app.py:99 | Disconnect and shut down\n",
      "INFO flower 2022-05-30 13:52:23,751 | app.py:99 | Disconnect and shut down\n",
      "INFO flower 2022-05-30 13:52:23,751 | app.py:99 | Disconnect and shut down\n",
      "INFO flower 2022-05-30 13:52:23,751 | app.py:99 | Disconnect and shut down\n",
      "INFO flower 2022-05-30 13:52:23,751 | app.py:99 | Disconnect and shut down\n",
      "INFO flower 2022-05-30 13:52:23,751 | app.py:99 | Disconnect and shut down\n",
      "INFO flower 2022-05-30 13:52:23,751 | app.py:99 | Disconnect and shut down\n",
      "INFO flower 2022-05-30 13:52:23,751 | app.py:99 | Disconnect and shut down\n",
      "INFO flower 2022-05-30 13:52:23,751 | app.py:99 | Disconnect and shut down\n",
      "INFO flower 2022-05-30 13:52:23,751 | app.py:99 | Disconnect and shut down\n",
      "INFO flower 2022-05-30 13:52:23,751 | app.py:99 | Disconnect and shut down\n",
      "DEBUG flower 2022-05-30 13:52:23,751 | connection.py:121 | gRPC channel closed\n",
      "INFO flower 2022-05-30 13:52:23,752 | app.py:99 | Disconnect and shut down\n",
      "DEBUG flower 2022-05-30 13:52:23,755 | connection.py:121 | gRPC channel closed\n",
      "INFO flower 2022-05-30 13:52:23,755 | app.py:99 | Disconnect and shut down\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 'vitrolife_federated_qfed.py' --ExperimentName=\"Embryo-R3-E1-B16-OverSampling-DA-QFed\" \\\n",
    "                                    --NumberOfClients=23 \\\n",
    "                                    --FractionOfClients=1 \\\n",
    "                                    --NumberOfRounds=3 \\\n",
    "                                    --BalancingStrategy=\"OverSampling\" \\\n",
    "                                    --DataAugmentation=\"True\" \\\n",
    "                                    --BatchSize=16 \\\n",
    "                                    --NumberOfEpochs=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c30c3c-3eb0-44a7-bf5b-1e251a1a66e8",
   "metadata": {},
   "source": [
    "### Load final model and apply test set \"federated eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e40b313-6e31-4c93-b730-13e58c1e011c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14144de5-c6ff-47c3-8c10-bf74370a2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import client.vitrolife.vitrolife_client as Client\n",
    "import server.vitrolife.vitrolife_server as Server\n",
    "\n",
    "list_train = []\n",
    "for i in range(23):\n",
    "\n",
    "    client = Client.VitrolifeClient(i, 5, 2, \"test\",  balancing_strategy=\"OverSampling\", use_data_augmentor=\"False\", batch_size=32)\n",
    "    \n",
    "    training_data = client.training_generator.__len__()\n",
    "    \n",
    "    #client.evaluate(None, None)\n",
    "    list_train.append((training_data, f\"client.-{i}\"))\n",
    "\n",
    "\n",
    "list_train.sort()\n",
    "print(list_train)\n",
    "#result = client.evaluate(None, None)\n",
    "\n",
    "#print(result)\n",
    "#model = client.model\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563063c0-aff8-49bf-8724-94f1b70b2bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "#print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1995c768-bf08-4bb2-ae38-33726e11a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from numpy import save\n",
    "from numpy import asarray\n",
    "from numpy import load\n",
    "\n",
    "import random as random\n",
    "import time\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import logging\n",
    "\n",
    "def eval_metrics_aggregate(result):\n",
    "    print(\"Server Last round metrics aggregation\")\n",
    "    fullpath = \"/mnt/data/FederatedLearning/client/vitrolife/clientLogs\"\n",
    "\n",
    "    ground_truths = []\n",
    "    predicted = []\n",
    "\n",
    "    ground_truths_matrix = []\n",
    "    predicted_matrix = []\n",
    "\n",
    "    for client_id in range(23):\n",
    "        current_predicted = load(f\"{fullpath}/predicted_{client_id}.npy\")\n",
    "        current_ground = load(f\"{fullpath}/ground_{client_id}.npy\")\n",
    "        print(\"Loading done\")\n",
    "\n",
    "        # Be aware of max sampling warning\n",
    "        current_ground = current_ground.tolist()\n",
    "        current_predicted = current_predicted.tolist()\n",
    "\n",
    "\n",
    "        ground_truths_matrix.extend(current_ground)\n",
    "        predicted_matrix.extend(current_predicted)\n",
    "\n",
    "        ground_truths.extend(current_ground)\n",
    "        predicted.extend(current_predicted)               \n",
    "\n",
    "    predicted_arg_max = []\n",
    "    predicted_probabilities_transformed = []\n",
    "\n",
    "    for proba in predicted:\n",
    "        proba = proba[0]\n",
    "        predicted_probabilities_transformed.append([1-proba, proba])\n",
    "        if proba > 0.5:\n",
    "            predicted_arg_max.append(1)\n",
    "        else:\n",
    "            predicted_arg_max.append(0)\n",
    "\n",
    "    predicted_arg_max = [proba.index(max(proba)) for proba in predicted_matrix]\n",
    "    classes = ['No Pregnancy', 'Pregnancy']       \n",
    "\n",
    "    wandb.sklearn.plot_confusion_matrix(ground_truths, predicted_arg_max, labels=classes)\n",
    "    wandb.log({\"roc\" : wandb.plot.roc_curve(ground_truths, predicted_probabilities_transformed, labels=classes)})\n",
    "\n",
    "    # wait for confustion to finsih\n",
    "    time.sleep(10)\n",
    "    wandb.finish()\n",
    "                \n",
    "        \n",
    "        \n",
    "experiment_name = \"TestPeter\"\n",
    "wandb.init(project=experiment_name, entity=\"anton-peter\")\n",
    "wandb.run.name = f\"Vitrolife Aggregation-Server\"\n",
    "eval_metrics_aggregate(None)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2581072c-d79e-401c-8b18-8805a49d209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import client.vitrolife.vitrolife_client as Client\n",
    "import server.vitrolife.vitrolife_server as Server\n",
    "\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "import utils.dataloaders.vitrolife_dataloader as DataLoader\n",
    "import utils.models.vitrolife_model as Model\n",
    "\n",
    "\n",
    "batz_size = 32\n",
    "balancing_strategy = \"OverSampling\"\n",
    "training_loader = DataLoader.VitroLifeDataloader(\"/mnt/data/vitroLifeDataset\", batz_size , dataset_split=\"Train\", data_augmentation = \"False\", balancing_strategy=balancing_strategy)\n",
    "validation_loader = DataLoader.VitroLifeDataloader(\"/mnt/data/vitroLifeDataset\", batz_size ,  dataset_split=\"Validation\", data_augmentation = \"False\", clinic_ID =2)\n",
    "testing_loader = DataLoader.VitroLifeDataloader(\"/mnt/data/vitroLifeDataset\", batz_size , dataset_split=\"Test\", data_augmentation = \"False\", clinic_ID =2)\n",
    "\n",
    "print(f\"training count {training_loader.count()}\")\n",
    "print(f\"validation count {validation_loader.count()}\")\n",
    "print(f\"test count {testing_loader.count()}\")\n",
    "\n",
    "\n",
    "testing_count = testing_loader.count()\n",
    "training_count = training_loader.count()\n",
    "total = testing_count + training_count\n",
    "\n",
    "print(f\"% of global data is test : {(testing_count/total)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a8c52-fbc3-4cc3-aca2-c1c08eb79925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../..')\n",
    "import utils.dataloaders.auto_flush as AutoFlush\n",
    "import utils.dataloaders.vitrolife_dataloader_old as DataLoader\n",
    "import utils.models.vitrolife_model as ModelLort\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Reshape\n",
    "from keras.models import Model\n",
    "\n",
    "METRICS = [\n",
    "    keras.metrics.TruePositives(name='tp'),\n",
    "    keras.metrics.FalsePositives(name='fp'),\n",
    "    keras.metrics.TrueNegatives(name='tn'),\n",
    "    keras.metrics.FalseNegatives(name='fn'), \n",
    "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(from_logits=True),\n",
    "    keras.metrics.AUC(name='prc', curve='PR', from_logits=True), # precision-recall curve\n",
    "]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), input_shape=(250,250,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256)) # W1*x + b\n",
    "model.add(Activation('relu')) # ReLU(W1*x + b)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1)) # W2*x + b\n",
    "model.add(Activation('sigmoid'))  # softmax(W2*x + b)\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.000001, decay=1e-6)\n",
    "\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=opt,\n",
    "              metrics=METRICS)\n",
    "        \n",
    "\n",
    "import resource\n",
    "class MemoryCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, log={}):\n",
    "        print(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "        \n",
    "batch_size = 32        \n",
    "training_generator = DataLoader.VitroLifeDataloader(\"/mnt/data/vitroLifeDataset\", batch_size , dataset_split=\"Train\", data_augmentation =\"False\" , balancing_strategy=\"None\", clinic_ID=0)\n",
    "validation_generator = DataLoader.VitroLifeDataloader(\"/mnt/data/vitroLifeDataset\", batch_size , dataset_split=\"Validation\", clinic_ID=0)\n",
    "\n",
    "model_gen = ModelLort.VitroLifeModel()\n",
    "model_from_gen = model_gen.get_low_GPU_mem_model() \n",
    "# ...\n",
    "#X_train = np.random.rand(5000, 250, 250, 1)\n",
    "#Y_train = np.random.randint(0, 2, size=5000)\n",
    "#X_test = np.random.rand(5000, 250, 250, 1)\n",
    "#Y_test = np.random.randint(0, 2, size=5000)\n",
    "\n",
    "list_x = []\n",
    "list_y = []\n",
    "for batches in range(training_generator.__len__()):\n",
    "    x, y = training_generator.__getitem__(batches)\n",
    "    #x, y = training_generator.__getitem__(batches)\n",
    "    list_x.extend(x)\n",
    "    list_y.extend(y)\n",
    "\n",
    "list_x = np.array(list_x) \n",
    "list_y = np.array(list_y) \n",
    "\n",
    "\n",
    "model_from_gen.fit(list_x, list_y, epochs=500, callbacks=[MemoryCallback()], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aedd0c-d7ad-4abd-97e0-55bcef2337ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(list_x, list_y, epochs=500, callbacks=[MemoryCallback(), AutoFlush.FlushCallback()], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e05433b-013d-4eed-b094-6eb361dcea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import client.vitrolife.vitrolife_client as Client\n",
    "\n",
    "\n",
    "client = Client.VitrolifeClient(0, 10, 10, \"test\", \"None\", \"false\", 32)\n",
    "\n",
    "lort = client.fit(None, None)\n",
    "\n",
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "\n",
    "client = Client.VitrolifeClient(0, 10, 10, \"test\", \"None\", \"false\", 32)\n",
    "\n",
    "lort = client.fit(None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8167ae8-956e-492c-baf1-5f0e7efc9fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ac5d7-ed0e-4815-a35b-cdf0db01040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow-text==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c23d29d-679c-4656-a2d3-d81e2f7a8bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71e9b26-3a0e-45f5-a095-3e466e30f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea52891c-834d-4018-871b-e3da0d8713c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from tensorflow import keras\n",
    "import numpy\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "\n",
    "# 0.0000001\n",
    "#model_name = \"Embryo-Centralized-B16-E100-No-LrSchedule/Epoch-97\"\n",
    "model_name = \"Embryo-Federated-B16-R100-E1-OverSampling/R-3\"\n",
    "model_from_disk = keras.models.load_model(f\"models/{model_name}\")\n",
    "print(K.eval(model_from_disk.optimizer.lr))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
